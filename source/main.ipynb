{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from data_loader import data_extractor\n",
    "from hcope import Hcope\n",
    "from mdp.environments import cartpole as cp\n",
    "from mdp.history import History\n",
    "from mdp.policies.f_policy import FBSoftmax\n",
    "from policy_evaluation import CartPoleEvaluation\n",
    "import hcope\n",
    "\n",
    "MODE = 1  # 0 for self generated; 1 for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 1 [ 0.01 -0.01  1.    1.  ] 200000\n",
      "(4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 4 (seed=302178, Thu Dec 12 15:30:55 2019)\n",
      "1,1,1,1 4.928283500659348\n"
     ]
    }
   ],
   "source": [
    "MODE = 1\n",
    "if MODE == 1:\n",
    "    num_state_features, num_actions, k, theta_b, num_episodes, states, actions, rewards, pi_b_St_At = data_extractor(\"../data/test_data/data.csv\")\n",
    "    print(num_state_features, num_actions, k, theta_b, num_episodes)\n",
    "    D = []\n",
    "    \n",
    "    num_episodes = 10\n",
    "    for i in range(num_episodes):\n",
    "        history = History(states[i], actions[i], rewards[i])\n",
    "        D.append(history)\n",
    "    \n",
    "    J_pi_b_hat = 0.0\n",
    "    for H in D:\n",
    "        J_pi_b_hat += np.sum(H.rewards)\n",
    "    \n",
    "    J_pi_b_hat /= len(D)\n",
    "    \n",
    "    policy = FBSoftmax(num_state_features,num_actions,k,0)\n",
    "    policy.parameters = theta_b\n",
    "    \n",
    "    hc = Hcope(D, policy, int(len(D)*0.5), J_pi_b_hat)\n",
    "    test_policy = FBSoftmax(num_state_features,num_actions,k,0)\n",
    "    test_policy.parameters = np.array([1,1,1,1])\n",
    "    ret = hc.test_pdis(test_policy)\n",
    "    print(\"1,1,1,1\", ret)\n",
    "    \n",
    "#     J_pi_b_hat = 0.0\n",
    "#     for H in D:\n",
    "#         J_pi_b_hat += np.sum(H.rewards)\n",
    "    \n",
    "#     J_pi_b_hat /= len(D)\n",
    "    \n",
    "#     for policy_number in range(10):\n",
    "        \n",
    "#         print(\"Trying \" + str(policy_number) + \"th policy\")\n",
    "    \n",
    "#         policy = FBSoftmax(num_state_features,num_actions,k,0)\n",
    "#         theta = hc.sample_theta_c()\n",
    "\n",
    "#         test_policy = FBSoftmax(num_state_features,num_actions,k,0)\n",
    "#         test_policy.parameters = theta\n",
    "#         ret = hc.test_pdis(test_policy)\n",
    "#         print(ret)\n",
    "#     #     hc.plot_es()\n",
    "    \n",
    "elif MODE == 0:\n",
    "    policy = FBSoftmax(4,2,1,0)\n",
    "    numEpisode = 1000\n",
    "\n",
    "    environment = cp.Cartpole\n",
    "\n",
    "    t = tabp_carp_evaluation(policy, environment)\n",
    "\n",
    "    mean_J_hat, D = t.run_policy(np.ones((2,5)), numEpisode)\n",
    "\n",
    "    print(\"Average J:\"+ str(mean_J_hat))\n",
    "\n",
    "     \n",
    "    hc = Hcope(D, policy, int(len(D)*0.4), 10)\n",
    "    for i in range(10):\n",
    "        print(\"step\",i)\n",
    "        theta = hc.sample_theta_c()\n",
    "        policy = FBSoftmax(4,2,1,0)\n",
    "        numEpisode = 100\n",
    "\n",
    "        environment = cp.Cartpole\n",
    "\n",
    "        t = CartPoleEvaluation(policy, environment)\n",
    "\n",
    "        mean_J_hat, D = t.run_policy(theta.reshape((2,5)), numEpisode)\n",
    "        print(\"theta: \", theta)\n",
    "        test_policy = FBSoftmax(num_state_features,num_actions,k,0)\n",
    "        test_policy.parameters = theta\n",
    "        ret = hc.test_pdis(test_policy)\n",
    "        print(\"pdis:\",ret)\n",
    "        print(\"Average J After:\"+ str(mean_J_hat))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
